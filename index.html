<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ziwei (Sara) Gong</title>

    <meta name="author" content="Sara Gong">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ziwei (Sara) Gong
                </p>
                <p>I am a second-year Ph.D. student in Computer Science at <a href="https://www.columbia.edu/">Columbia University</a> under the supervision of Professor <a href="https://www.cs.columbia.edu/speech/people.cgi?p=julia">Julia Hirschberg</a>.
                </p>
                <p>
                  My research interest is in multimodal learning and the interdisciplinary studies between NLP and psychology. Currently, I am working on multimodal emotion detection.
                </p>
                <p style="text-align:center">
                  <a href="mailto:zg2272@columbia.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/Sara_Gong_s_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/ZiweiGong-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=pF9WMYsAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ZiweiG/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/IMG_2504.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interest is in multimodal learning and the interdisciplinary studies between NLP and psychology. Currently, I am working on multimodal emotion detection.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	
    <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/bd_promo.jpg" alt="blind-date" width="160" height="160">
              </td>
              <td width="75%" valign="middle">
        <a href="https://aclanthology.org/2023.sicon-1.1/">
          <span class="papertitle">Eliciting Rich Positive Emotions in Dialogue Generation</span>
        </a>
        <br>
	        <strong>Ziwei Gong</strong>,
		<a href="https://taolusi.github.io/qingkai_min/">Qingkai Min</a>,
		<a href="https://frcchang.github.io/">Yue Zhang</a>
        <br>
	<em>SICon, First Workshop on Social Influence in Conversations, ACL</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://aclanthology.org/2023.sicon-1.1.pdf">pdf</a>
        <p></p>
        <p>
        Propose to model various emotions in large unannotated conversations, such as joy, trust and anticipation, by leveraging a latent variable to control the emotional intention of the response.
        </p>
      </td>
    </tr>
	
    <tr>
        <a href="https://www.cs.columbia.edu/speech/PaperFiles/2021/SocialSens2021_April18.pdf">
          <span class="papertitle">Exploring New Methods for Identifying False Information and the Intent Behind It on Social Media: COVID-19 Tweets</span>
        </a>
        <br>
		<a>Lin Ai,</a>,
		<a>Run Chen</a>,
		<strong>Ziwei Gong</strong>,
          <a> Julia Guo</a>,
          <a>Shayan Hooshmand</a>,
          <a>Zixiaofan Yang</a>,
          <a href="https://www.cs.columbia.edu/speech/people.cgi?p=julia">Julia Hirschberg</a>
        <br>
        <em>SocialSens, Sixth International Workshop on Social Sensing, ICWSM</em>, 2021
        <br>
        <a href="https://workshop-proceedings.icwsm.org/pdf/2021_31.pdf">pdf</a>
        <p></p>
      </td>
    </tr>

		  
      <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/zipnerf.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/zipnerf.jpg' width="160">
          </div>
          <script type="text/javascript">
            function zipnerf_start() {
              document.getElementById('zipnerf_image').style.opacity = "1";
            }

            function zipnerf_stop() {
              document.getElementById('zipnerf_image').style.opacity = "0";
            }
            zipnerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="http://jonbarron.info/zipnerf">
            <span class="papertitle">Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields</span>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>,
          <a href="https://bmild.github.io/">Ben Mildenhall</a>,
          <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
          <a href="https://phogzone.com/">Peter Hedman</a>
          <br>
          <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Finalist)</strong></font>
          <br>
          <a href="http://jonbarron.info/zipnerf">project page</a>
          /
          <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
          /
          <a href="https://arxiv.org/abs/2304.06706">arXiv</a>
          <p></p>
          <p>
          Combining mip-NeRF 360 and grid-based models like Instant NGP lets us reduce error rates by 8%&ndash;77% and accelerate training by 24x.
          </p>
        </td>
      </tr>
      
            <tr onmouseout="dualdefocus_stop()" onmouseover="dualdefocus_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dualdefocus_image'>
                    <img src='images/dualdefocus_after.jpg' width="160"></div>
                  <img src='images/dualdefocus_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dualdefocus_start() {
                    document.getElementById('dualdefocus_image').style.opacity = "1";
                  }

                  function dualdefocus_stop() {
                    document.getElementById('dualdefocus_image').style.opacity = "0";
                  }
                  dualdefocus_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://imaging.cs.cmu.edu/dual_pixels/">
                  <span class="papertitle">Defocus Map Estimation and Deblurring from a Single Dual-Pixel Image</span>
                </a>
                <br>
                <a href="https://shumianxin.github.io/">Shumian Xin</a>,
                <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
                <a href="https://tianfan.info/">Tianfan Xue</a>,
                <strong>Jonathan T. Barron</strong>, <br>
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
                <a href="https://www.cs.cmu.edu/~igkioule/">Ioannis Gkioulekas</a>,
                <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>
                <br>
                <em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                <br>
                <a href="https://imaging.cs.cmu.edu/dual_pixels/">project page</a> /
                <a href="https://github.com/cmu-ci-lab/dual_pixel_defocus_estimation_deblurring">code</a>
                <br>
                <p></p>
                <p>
                  Multiplane images can be used to simultaneously deblur dual-pixel images, despite variable defocus due to depth variation in the scene.
                </p>
              </td>
            </tr> 


          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
